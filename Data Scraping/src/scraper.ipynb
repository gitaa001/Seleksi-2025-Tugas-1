{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "37126221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Sukses menyimpan ranking ke '../data/raw/all_episodes_top12.json'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# ==========================================================\n",
    "#         TOP 12 ALL EPS (all_episodes_top12.json)\n",
    "# ==========================================================\n",
    "\n",
    "url = \"https://en.wikipedia.org/wiki/Produce_48\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, \"lxml\")\n",
    "\n",
    "# Cari tabel Top 12\n",
    "table = None\n",
    "for t in soup.find_all(\"table\", {\"class\": \"wikitable\"}):\n",
    "    headers = [th.get_text(strip=True) for th in t.find_all(\"th\")]\n",
    "    if headers and headers[0] == \"No.\" and \"Ep.1\" in headers:\n",
    "        table = t\n",
    "        break\n",
    "\n",
    "if not table:\n",
    "    raise Exception(\"❌ Tabel ranking tidak ditemukan.\")\n",
    "\n",
    "# Ambil isi tabel\n",
    "rows = table.find_all(\"tr\")[1:]\n",
    "episode_headers = [th.get_text(strip=True) for th in table.find_all(\"th\")][1:]\n",
    "\n",
    "data = []\n",
    "\n",
    "for row in rows:\n",
    "    cols = row.find_all(\"td\")\n",
    "    if not cols:\n",
    "        continue\n",
    "    rank_no = cols[0].get_text(strip=True)\n",
    "    for i, col in enumerate(cols[1:]):\n",
    "        episode = episode_headers[i]\n",
    "        # Ambil angka episode saja\n",
    "        episode_num = int(re.sub(r\"\\D\", \"\", episode))  # \"Ep.12\" -> 12\n",
    "        name = col.get_text(strip=True)\n",
    "\n",
    "        # cleaning nama\n",
    "        name = name.replace(\"-\", \"\")                  # hapus tanda \"-\"\n",
    "        name = re.sub(r\"\\s*[↑↓+\\-]\\d+\\s*$\", \"\", name) # hapus simbol \"↑1\", \"↓2\", \"+3\", \"-4\", dsb\n",
    "        name = re.split(r\"\\s*=\\s*\", name)[0]\n",
    "\n",
    "        if not name:\n",
    "            continue\n",
    "        # Kolom pertama episode, lalu name, lalu rank\n",
    "        data.append({\n",
    "            \"episode\": episode_num,\n",
    "            \"name\": name,\n",
    "            \"rank\": rank_no\n",
    "        })\n",
    "\n",
    "# Simpan ke JSON\n",
    "output_dir = \"../data/raw\"\n",
    "output_file = \"all_episodes_top12.json\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "with open(os.path.join(output_dir, output_file), \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(data, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "print(f\"✅ Sukses menyimpan ranking ke '{output_dir}/{output_file}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "96db3331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jumlah tabel: 17\n",
      "3 ['8D Creative (에잇디크리에이티브)', 'Kang Hyewon (강혜원)', np.int64(19), 'F', 'F', np.int64(38), np.int64(40), '41', '25', '222716', '3', '927362', '3', '4', '311212', '8', '248432', np.int64(8)]\n",
      "4 [np.int64(1), 'GFriend', '\"Love Whisper\"', '칠전팔기 (Never Give Up!)', '334', 'Sub vocal 2', 'Son Eunchae', np.int64(88), np.float64(nan), np.float64(nan)]\n",
      "5 ['Vocal & Rap', np.int64(1), 'Wanna One', '\"Energetic\"', 'Na Goeun', '382', np.int64(2), nan, np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "6 [np.int64(1), 'Contemporary Girls Pop', 'oReO', '\"1000%\"', np.int64(138), 'Sub vocal 2', 'Moe Goto', np.int64(28), np.int64(19), np.float64(nan)]\n",
      "7 [np.int64(1), 'Yasushi Akimoto', '\"Suki ni Nacchau Darō? (반해버리잖아? / 好きになっちゃうだろう？)\"', 'Sub vocal 2', 'Sakura Miyawaki']\n",
      "8 ['China', 'Produce 101 China Chuang 2019 Chuang 2020 Chuang 2021']\n",
      "10 ['48 (IZ*ONE)', 'Jang Won-young Sakura Miyawaki Jo Yu-ri Choi Ye-na An Yu-jin Nako Yabuki Kwon Eun-bi Kang Hye-won Hitomi Honda Kim Chaewon Kim Min-ju Lee Chae-yeon']\n",
      "11 ['48', 'Alex Christine Hong Ye-ji Huh Yunjin Jang Gyu-ri Juri Takahashi Jurina Matsui Kim Do-ah Kim Si-hyeon Mako Kojima Miho Miyazaki Miru Shiroma Miyu Takeuchi Rena Hasegawa Sae Murase Shin Su-hyun Tomu Muto Yūka Kato']\n",
      "14 ['Official Members', \"Saho Iwatate Seina Fukuoka Mion Mukaichi Yui Oguri Narumi Kuranoo (AKB48's Captain & AKB48 Group's\\xa0General Manager) Hiyuka Sakagawa Miu Shitao Ayane Takahashi Remi Tokunaga Serika Nagano Haruna Hashimoto Erii Chiba Kurumi Suzuki Manaka Taguchi Ayami Nagatomo Orin Muto Mizuki Yamauchi Maho Omori Yuki Ota Airi Satō Eriko Hashimoto Nozomi Hatakeyama Yuki Hirata Moka Hotei Mayu Masai Miyu Mizushima Sora Yamazaki Yuna Akiyama Sae Arai Kasumi Kudō Hinano Kubo Yumemi Sako Kohina Narita Azuki Yagi Yui Yamaguchi Manaka Taguchi\"]\n",
      "15 ['Kenkyuusei', 'Momoka Ito Kairi Okumoto Yui Kawamura Sari Shiratori Mei Hanada Saki Oga Saki Kondo Hinata Maruyama']\n"
     ]
    }
   ],
   "source": [
    "# CEK TABEL\n",
    "import pandas as pd\n",
    "\n",
    "tables = pd.read_html(\"https://en.wikipedia.org/wiki/List_of_Produce_48_contestants\", header=None)\n",
    "print(\"Jumlah tabel:\", len(tables))\n",
    "for i, tbl in enumerate(tables):\n",
    "    # Kecualikan tabel terlalu kecil barisnya\n",
    "    if tbl.shape[0] > 3:\n",
    "        print(i, tbl.iloc[2].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b24ad587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sukses simpan 768 trainee per episode ke 'trainee_episode_rank.json'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Load semua tabel dari Wikipedia\n",
    "url = \"https://en.wikipedia.org/wiki/List_of_Produce_48_contestants\"\n",
    "tables = pd.read_html(url)\n",
    "\n",
    "# Ambil tabel ke-4 (index ke-3)\n",
    "df = tables[3]\n",
    "\n",
    "# Ubah nama kolom, tambahkan koma yang hilang di ep1_rank dan ep2_rank\n",
    "df.columns = [\n",
    "    \"company\", \"name\", \"age\", \"1st_grade\", \"last_grade\", \n",
    "    \"ep1_rank\", \"ep2_rank\", \"ep3_rank\", \"ep5_rank\", \n",
    "    \"ep5_votes\", \"ep8_rank\", \"ep8_votes\", \n",
    "    \"ep10_rank\", \"ep11_rank\", \"ep11_votes\", \n",
    "    \"ep12_rank\", \"total_votes\", \"final_rank\"\n",
    "]\n",
    "\n",
    "# Pilih kolom yang relevan\n",
    "data = df[[\n",
    "    \"name\", \"ep1_rank\", \"ep2_rank\", \"ep3_rank\", \"ep5_rank\", \n",
    "    \"ep8_rank\", \"ep10_rank\", \"ep11_rank\", \"ep12_rank\"\n",
    "]].copy()\n",
    "\n",
    "# Ganti \"-\" dan NaN jadi None, dan handle \"Eliminated\"\n",
    "for col in data.columns[1:]:\n",
    "    data[col] = data[col].apply(lambda x: \n",
    "        \"eliminated\" if isinstance(x, str) and \"eliminated\" in x.lower() \n",
    "        else (None if x == \"-\" or pd.isna(x) else x)\n",
    "    )\n",
    "\n",
    "# Hapus baris kosong total\n",
    "data = data.dropna(how=\"all\")\n",
    "\n",
    "# Buang duplikat berdasarkan 'name' dan 'final_rank'\n",
    "data = data.drop_duplicates(subset=[\"name\", \"ep12_rank\"])\n",
    "\n",
    "# Ubah ke long format\n",
    "rank_long = data.melt(id_vars='name', var_name='episode', value_name='rank')\n",
    "rank_long = rank_long.dropna(subset=['rank'])\n",
    "\n",
    "# Ekstrak nomor episode dari nama kolom, contoh: \"ep1_rank\" -> 1\n",
    "rank_long['episode'] = rank_long['episode'].str.extract(r'ep(\\d+)_rank')\n",
    "rank_long['episode'] = pd.to_numeric(rank_long['episode'], errors='coerce')\n",
    "rank_long = rank_long.dropna(subset=['episode'])\n",
    "\n",
    "# Ubah tipe data episode ke int\n",
    "rank_long['episode'] = rank_long['episode'].astype(int)\n",
    "\n",
    "# Pastikan rank \"eliminated\" tetap string, selain itu ubah ke int\n",
    "def clean_rank(val):\n",
    "    if isinstance(val, str) and val.lower() == \"eliminated\":\n",
    "        return \"eliminated\"\n",
    "    try:\n",
    "        return int(val)\n",
    "    except:\n",
    "        return val\n",
    "\n",
    "rank_long['rank'] = rank_long['rank'].apply(clean_rank)\n",
    "\n",
    "# Ubah ke dict\n",
    "records = rank_long.to_dict(orient=\"records\")\n",
    "\n",
    "# Simpan\n",
    "output_dir = \"../data/raw\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_file = \"trainee_episode_rank.json\"\n",
    "\n",
    "with open(os.path.join(output_dir, output_file), \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(records, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "print(f\"Sukses simpan {len(records)} trainee per episode ke '{output_file}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2934567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Sukses simpan 96 trainee ke 'trainee.json'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_24780\\1318353989.py:32: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df = df.fillna(method=\"ffill\")\n"
     ]
    }
   ],
   "source": [
    "# ==============================================\n",
    "#         DATA TRAINEE (trainee.json)\n",
    "# ==============================================\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Load semua tabel\n",
    "url = \"https://produce101.fandom.com/wiki/Season_3_Contestants\"\n",
    "tables = pd.read_html(url)\n",
    "\n",
    "# Ambil tabel pertama\n",
    "df = tables[0]\n",
    "\n",
    "# Rename kolom\n",
    "df.columns = [\n",
    "    \"nationality\", \"company\", \"name\", \"korean_name\", \"japanese_name\",\n",
    "    \"age\", \"1st_grade\", \"last_grade\", \"1st_rank\", \"final_rank\"\n",
    "]\n",
    "\n",
    "# CLEANING\n",
    "# ada beberapa kolom yg lebih baik bertipe integer\n",
    "# kolom yg berisi \"-\", diganti \"\"\n",
    "df = df.replace(\"-\", \"\")\n",
    "df['age'] = df['age'].astype('Int64')    \n",
    "df['1st_rank'] = df['1st_rank'].astype('Int64')\n",
    "\n",
    "# Hapus baris kosong total\n",
    "df = df.dropna(how=\"all\")\n",
    "# Forward fill\n",
    "df = df.fillna(method=\"ffill\")\n",
    "\n",
    "# Hapus baris duplikat berdasarkan kolom 'name' dan 'final_rank'\n",
    "df = df.drop_duplicates(subset=[\"name\", \"final_rank\"])\n",
    "\n",
    "\n",
    "records = df.to_dict(orient=\"records\")\n",
    "\n",
    "# Simpan\n",
    "output_dir = \"../../data\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_file = \"trainee.json\"\n",
    "\n",
    "with open(os.path.join(output_dir, output_file), \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(records, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "print(f\"Sukses simpan {len(records)} trainee ke '{output_file}'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15acfd8e",
   "metadata": {},
   "source": [
    "<h3> DATA PERFORMANCE </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ee33c5b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jumlah tabel: 12\n",
      "0 [np.int64(3), 'Jo Yuri', 'Stone Music Entertainment', np.int64(294734)]\n",
      "1 [np.float64(nan), 'Eliminated in Episode 11']\n",
      "2 ['AKB48', 'Team A', 'Shinozaki Ayana', 'F', 'F', np.float64(84.0), np.float64(87.0), '77', '91 (30,489)', 'Eliminated', 'Eliminated', 'Eliminated', 'Eliminated']\n",
      "3 ['Starship Entertainment', 'Jang Wonyoung', np.int64(15), 'B', 'B', np.int64(3), np.int64(4), np.int64(4), '3 (539,596)', '1 (1,010,555)', np.int64(8), '7 (277,922)', '1 (338,366)']\n",
      "4 [np.float64(nan), 'Center']\n",
      "5 [np.int64(1), 'GFRIEND', '\"Love Whisper\"', 'ChilJeonPalgi (칠전팔기)', '334', 'Sub vocal 2', 'Son Eunchae', np.int64(88), np.float64(nan), np.float64(nan)]\n",
      "6 [np.float64(nan), 'Center']\n",
      "7 ['Vocal & Rap', np.int64(1), 'Wanna One', '\"Energetic\"', 'Na Goeun', np.float64(382.0), np.int64(2), nan, np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "9 [np.int64(1), 'Contemporary Girls Pop', 'oReO', '\"1000%\"', np.int64(138), 'Sub vocal 2', 'Goto Moe', np.int64(28), np.int64(19), np.float64(nan)]\n",
      "11 [np.int64(1), 'Akimoto Yasushi', '\"Suki ni Nacchau Darou? (반해버리잖아? / 好きになっちゃうだろう？)\"', 'Sub vocal 2', 'Miyawaki Sakura']\n"
     ]
    }
   ],
   "source": [
    "# CEK TABEL\n",
    "import pandas as pd\n",
    "\n",
    "tables = pd.read_html(\"https://akb48.fandom.com/wiki/Produce_48\", header=None)\n",
    "print(\"Jumlah tabel:\", len(tables))\n",
    "for i, tbl in enumerate(tables):\n",
    "    # Kecualikan tabel terlalu kecil barisnya\n",
    "    if tbl.shape[0] > 3:\n",
    "        print(i, tbl.iloc[2].tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f376acc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw table columns: [0, 1, 2, 3, 4]\n",
      "Sample rows:\n",
      "                  0                1                2                           3                4\n",
      "0  Korean Trainees  Korean Trainees  Korean Trainees             Korean Trainees  Korean Trainees\n",
      "1          Company         Trainees            Grade                        Song             Link\n",
      "2      Independent    Park Seoyoung                C  \"Roller Coaster\" - Chungha       Video Link\n",
      "✅ Successfully saved 98 records to individual_evaluation.json\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "#     INDIVIDUAL EVALUATION (individual_evaluation.json)\n",
    "# ==========================================================\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "\n",
    "# Fetch tables\n",
    "tables = pd.read_html(\"https://produce101.fandom.com/wiki/Produce_48_Company_Evaluation\")\n",
    "\n",
    "# Ambil tabel posisi evaluasi (pastikan ini benar)\n",
    "position_table = tables[0]  # konfirmasi berdasarkan struktur tabel\n",
    "\n",
    "# Tampilkan struktur mentah untuk debugging (bisa di-comment kalau udah oke)\n",
    "print(\"Raw table columns:\", position_table.columns.tolist())\n",
    "print(\"Sample rows:\\n\", position_table.head(3).to_string())\n",
    "\n",
    "# Ambil header dari baris ke-2 dan data mulai baris ke-3\n",
    "headers = position_table.iloc[1]\n",
    "data = position_table.iloc[2:].copy()\n",
    "\n",
    "# Atur kolom manual\n",
    "data.columns = [\n",
    "    \"company\",\n",
    "    \"name\",\n",
    "    \"grade\",\n",
    "    \"song\",\n",
    "    \"link\"\n",
    "]\n",
    "\n",
    "data = data[[\"company\",\"name\", \"grade\", \"song\"]]\n",
    "\n",
    "# cleaning kolom song\n",
    "def clean_quotes(song):\n",
    "    if isinstance(song, str):\n",
    "        # Hapus kutip ganda hanya di sekitar judul lagu\n",
    "        return re.sub(r'^\"(.*?)\"\\s*-\\s*(.*)$', r'\\1 - \\2', song).strip()\n",
    "    return song\n",
    "\n",
    "data['song'] = data['song'].apply(clean_quotes)\n",
    "\n",
    "# Hapus baris kosong total\n",
    "data = data.dropna(how='all').reset_index(drop=True)\n",
    "\n",
    "# Ganti semua NaN (kosong) menjadi string kosong \"\"\n",
    "data = data.fillna(\"\")\n",
    "\n",
    "# Convert ke records (list of dict)\n",
    "records = data.to_dict(orient='records')\n",
    "\n",
    "# Simpan ke file JSON\n",
    "output_dir = \"../../data\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_file = \"individual_evaluation.json\"\n",
    "\n",
    "with open(os.path.join(output_dir, output_file), 'w', encoding='utf-8') as f:\n",
    "    json.dump(records, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"✅ Successfully saved {len(records)} records to {output_file}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "19e54ea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw table columns: [('Performance', '#'), ('Performance', 'Artist'), ('Performance', 'Song'), ('Team', 'Name'), ('Team', 'Votes (Average)'), ('Contestant', 'Position'), ('Contestant', 'Name'), ('Contestant', 'Votes'), ('Contestant', 'Bonus'), ('Contestant', 'Unnamed: 9_level_1')]\n",
      "Sample rows:\n",
      "   Performance                                           Team                   Contestant                                            \n",
      "            #   Artist            Song                  Name Votes (Average)     Position         Name Votes Bonus Unnamed: 9_level_1\n",
      "0           1  GFRIEND  \"Love Whisper\"  ChilJeonPalgi (칠전팔기)             334   Main vocal      Wang Ke    28   NaN                NaN\n",
      "1           1  GFRIEND  \"Love Whisper\"  ChilJeonPalgi (칠전팔기)             334  Sub vocal 1    Muto Tomu    52   NaN                NaN\n",
      "2           1  GFRIEND  \"Love Whisper\"  ChilJeonPalgi (칠전팔기)             334  Sub vocal 2  Son Eunchae    88   NaN                NaN\n",
      "✅ Successfully saved 92 records to group_battle_evaluation.json\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import os\n",
    "\n",
    "# ==========================================================\n",
    "#     GROUP BATTLE EVALUATION (group_battle_evaluation.json)\n",
    "# ==========================================================\n",
    "\n",
    "# Fetch tables\n",
    "tables = pd.read_html(\"https://akb48.fandom.com/wiki/Produce_48\")\n",
    "\n",
    "# Ambil tabel posisi evaluasi \n",
    "position_table = tables[5] \n",
    "\n",
    "# Tampilkan struktur mentah untuk debugging (bisa di-comment kalau udah oke)\n",
    "print(\"Raw table columns:\", position_table.columns.tolist())\n",
    "print(\"Sample rows:\\n\", position_table.head(3).to_string())\n",
    "\n",
    "# Ambil header dari baris ke-2 dan data mulai baris ke-1\n",
    "headers = position_table.iloc[1]\n",
    "data = position_table.iloc[0:].copy()\n",
    "\n",
    "# Atur kolom manual\n",
    "data.columns = [\n",
    "    \"id_perform\",\n",
    "    \"original_artist\", \n",
    "    \"song\", \n",
    "    \"team_name\", \n",
    "    \"team_votes\", \n",
    "    \"trainee_position\",\n",
    "    \"trainee_name\", \n",
    "    \"trainee_votes\", \n",
    "    \"trainee_bonus\",\n",
    "    \"unused\"\n",
    "]\n",
    "\n",
    "data = data[[\"id_perform\", \"original_artist\", \"song\", \"team_name\", \"team_votes\", \n",
    "    \"trainee_position\", \"trainee_name\", \"trainee_votes\", \"trainee_bonus\"]]\n",
    "\n",
    "# Hapus baris kosong total\n",
    "data = data.dropna(how='all').reset_index(drop=True)\n",
    "\n",
    "# cleaning kolom angka\n",
    "def safe_int(val):\n",
    "    if pd.isna(val) or val == \"\":\n",
    "        return 0\n",
    "    # Ambil digit dengan regex\n",
    "    digits = re.sub(r\"[^\\d]\", \"\", str(val))\n",
    "    return int(digits) if digits else 0\n",
    "\n",
    "data['trainee_bonus'] = data['trainee_bonus'].apply(safe_int)\n",
    "\n",
    "# cleaning kolom song\n",
    "def clean_quotes(text):\n",
    "    if isinstance(text, str):\n",
    "        text = text.strip()\n",
    "        # Hilangkan hanya kutip ganda luar, tapi biarkan apostrof (kutip tunggal)\n",
    "        if text.startswith('\"') and text.endswith('\"'):\n",
    "            return text[1:-1]\n",
    "    return text\n",
    "\n",
    "data['song'] = data['song'].apply(clean_quotes)\n",
    "\n",
    "# Ganti semua NaN (kosong) menjadi string kosong \"\"\n",
    "data = data.fillna(\"\")\n",
    "\n",
    "# Convert ke records (list of dict)\n",
    "records = data.to_dict(orient='records')\n",
    "\n",
    "# Simpan ke file JSON\n",
    "output_dir = \"../../data\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_file = \"group_battle_evaluation.json\"\n",
    "\n",
    "with open(os.path.join(output_dir, output_file), 'w', encoding='utf-8') as f:\n",
    "    json.dump(records, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"✅ Successfully saved {len(records)} records to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "8094409a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw table columns: [('Performance', 'Position'), ('Performance', '#'), ('Performance', 'Artist'), ('Performance', 'Song'), ('Name', 'Name'), ('Results', 'Votes'), ('Results', 'Rank'), ('Results', 'Bonus'), ('Results', 'Unnamed: 8_level_1'), ('Results', 'Unnamed: 9_level_1'), ('Results', 'Unnamed: 10_level_1')]\n",
      "Sample rows:\n",
      "    Performance                                    Name Results                                                                      \n",
      "      Position  #     Artist         Song         Name   Votes Rank  Bonus Unnamed: 8_level_1 Unnamed: 9_level_1 Unnamed: 10_level_1\n",
      "0  Vocal & Rap  1  Wanna One  \"Energetic\"      Jo Yuri   511.0    1  +5000                NaN                NaN                 NaN\n",
      "1  Vocal & Rap  1  Wanna One  \"Energetic\"  Kim Sihyeon   376.0    3    NaN                NaN                NaN                 NaN\n",
      "2  Vocal & Rap  1  Wanna One  \"Energetic\"     Na Goeun   382.0    2    NaN                NaN                NaN                 NaN\n",
      "✅ Successfully saved 57 records to position_evaluation.json\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "#     POSITION EVALUATION (position_evaluation.json)\n",
    "# ==========================================================\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "\n",
    "# Fetch tables\n",
    "tables = pd.read_html(\"https://akb48.fandom.com/wiki/Produce_48\")\n",
    "\n",
    "# Ambil tabel posisi evaluasi (pastikan ini benar)\n",
    "position_table = tables[7]  # konfirmasi berdasarkan struktur tabel\n",
    "\n",
    "# Tampilkan struktur mentah untuk debugging (bisa di-comment kalau udah oke)\n",
    "print(\"Raw table columns:\", position_table.columns.tolist())\n",
    "print(\"Sample rows:\\n\", position_table.head(3).to_string())\n",
    "\n",
    "# Ambil header dari baris ke-2 dan data mulai baris ke-1\n",
    "headers = position_table.iloc[0]\n",
    "data = position_table.iloc[0:].copy()\n",
    "\n",
    "# Atur kolom manual\n",
    "data.columns = [\n",
    "    \"category\", \n",
    "    \"id_perform\", \n",
    "    \"original_artist\", \n",
    "    \"song\", \n",
    "    \"trainee_name\", \n",
    "    \"trainee_votes\", \n",
    "    \"rank_in_team\", \n",
    "    \"trainee_bonus\",\n",
    "    \"results_8\",\n",
    "    \"results_9\",\n",
    "    \"results_10\"\n",
    "]\n",
    "\n",
    "data = data[[\"category\", \"id_perform\", \"original_artist\", \"song\", \"trainee_name\", \"trainee_votes\", \"rank_in_team\", \"trainee_bonus\",]]\n",
    "\n",
    "# Hapus baris kosong total\n",
    "data = data.dropna(how='all').reset_index(drop=True)\n",
    "\n",
    "# cleaning kolom Bonus\n",
    "def safe_int(val):\n",
    "    if pd.isna(val) or val == \"\":\n",
    "        return 0\n",
    "    # Ambil digit dengan regex\n",
    "    digits = re.sub(r\"[^\\d]\", \"\", str(val))\n",
    "    return int(digits) if digits else 0\n",
    "\n",
    "data['trainee_bonus'] = data['trainee_bonus'].apply(safe_int)\n",
    "\n",
    "# cleaning kolom song\n",
    "def clean_quotes(text):\n",
    "    if isinstance(text, str):\n",
    "        text = text.strip()\n",
    "        # Hilangkan hanya kutip ganda luar, tapi biarkan apostrof (kutip tunggal)\n",
    "        if text.startswith('\"') and text.endswith('\"'):\n",
    "            return text[1:-1]\n",
    "    return text\n",
    "\n",
    "data['song'] = data['song'].apply(clean_quotes)\n",
    "\n",
    "# Ganti semua NaN (kosong) menjadi string kosong \"\"\n",
    "data = data.fillna(\"\")\n",
    "\n",
    "# Convert ke records (list of dict)\n",
    "records = data.to_dict(orient='records')\n",
    "\n",
    "# Simpan ke file JSON\n",
    "output_dir = \"../../data\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_file = \"position_evaluation.json\"\n",
    "\n",
    "with open(os.path.join(output_dir, output_file), 'w', encoding='utf-8') as f:\n",
    "    json.dump(records, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"✅ Successfully saved {len(records)} records to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "874e6699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kolom awal: [('Performance', '#'), ('Performance', 'Concept'), ('Performance', 'Producer'), ('Performance', 'Song'), ('Performance', 'Votes'), ('Contestant', 'Position'), ('Contestant', 'Name'), ('Contestant', 'Votes'), ('Contestant', 'Rank'), ('Contestant', 'Bonus')]\n",
      "Contoh baris:\n",
      "   Performance                                                   Contestant                                \n",
      "            #                 Concept Producer     Song Votes     Position           Name Votes Rank Bonus\n",
      "0           1  Contemporary Girls Pop     oReO  \"1000%\"   138   Main vocal   Lee Chaeyeon    18   24   NaN\n",
      "1           1  Contemporary Girls Pop     oReO  \"1000%\"   138  Sub vocal 1  Miyazaki Miho    42   13   NaN\n",
      "2           1  Contemporary Girls Pop     oReO  \"1000%\"   138  Sub vocal 2       Goto Moe    28   19   NaN\n",
      "[   nan 20000. 50000.]\n",
      "✅ Sukses simpan 30 baris ke concept_evaluation.json\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "#     CONCEPT EVALUATION (concept_evaluation.json)\n",
    "# ==========================================================\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "\n",
    "# Ambil semua tabel dari Fandom Wiki\n",
    "tables = pd.read_html(\"https://akb48.fandom.com/wiki/Produce_48\")\n",
    "\n",
    "# Pilih tabel Concept Evaluation (tabel ke-9)\n",
    "table = tables[9]\n",
    "\n",
    "# Cek struktur awal (opsional)\n",
    "print(\"Kolom awal:\", table.columns.tolist())\n",
    "print(\"Contoh baris:\\n\", table.head(3).to_string())\n",
    "\n",
    "# Ambil data dari baris ke-3 ke bawah\n",
    "data = table.iloc[0:].copy()\n",
    "\n",
    "# Rename kolom secara manual\n",
    "data.columns = [\n",
    "    \"id_perform\",\n",
    "    \"concept\",\n",
    "    \"producer\",\n",
    "    \"original_single\",\n",
    "    \"votes\",\n",
    "    \"trainee_position\",\n",
    "    \"trainee_name\",\n",
    "    \"trainee_votes\",\n",
    "    \"trainee_rank\",\n",
    "    \"bonus\"\n",
    "]\n",
    "\n",
    "# Drop baris yang kosong total\n",
    "data = data.dropna(how='all').reset_index(drop=True)\n",
    "\n",
    "print(data[\"bonus\"].unique()[:10]) #ngecek\n",
    "\n",
    "# cleaning kolom angka\n",
    "def safe_int(val):\n",
    "    if pd.isna(val) or val == \"\":\n",
    "        return 0\n",
    "    # Ambil digit dengan regex\n",
    "    digits = re.sub(r\"[^\\d]\", \"\", str(val))\n",
    "    return int(digits) if digits else 0\n",
    "\n",
    "# cleaning int\n",
    "data['votes'] = data['votes'].apply(safe_int)\n",
    "data['bonus'] = data['bonus'].apply(safe_int)\n",
    "data['trainee_rank'] = data['trainee_rank'].apply(safe_int)\n",
    "data['trainee_votes'] = data['trainee_votes'].apply(safe_int)\n",
    "\n",
    "# cleaning kolom song\n",
    "def clean_quotes(text):\n",
    "    if isinstance(text, str):\n",
    "        text = text.strip()\n",
    "        # Hilangkan hanya kutip ganda luar, tapi biarkan apostrof (kutip tunggal)\n",
    "        if text.startswith('\"') and text.endswith('\"'):\n",
    "            return text[1:-1]\n",
    "    return text\n",
    "\n",
    "data['original_single'] = data['original_single'].apply(clean_quotes)\n",
    "\n",
    "# Ganti NaN lainnya dengan string kosong\n",
    "data = data.fillna(\"\")\n",
    "\n",
    "# Konversi ke list of dict\n",
    "records = data.to_dict(orient='records')\n",
    "\n",
    "# Simpan ke file JSON\n",
    "output_dir = \"../data/raw\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_file = \"concept_evaluation.json\"\n",
    "\n",
    "with open(os.path.join(output_dir, output_file), \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(records, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"✅ Sukses simpan {len(records)} baris ke {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "700295f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kolom awal: [('Performance', '#'), ('Performance', 'Producer'), ('Performance', 'Song'), ('Contestant', 'Position'), ('Contestant', 'Name')]\n",
      "Contoh data:\n",
      "   Performance                                                                       Contestant                 \n",
      "            #         Producer                                               Song     Position             Name\n",
      "0           1  Akimoto Yasushi  \"Suki ni Nacchau Darou? (반해버리잖아? / 好きになっちゃうだろう？)\"   Main vocal       Kwon Eunbi\n",
      "1           1  Akimoto Yasushi  \"Suki ni Nacchau Darou? (반해버리잖아? / 好きになっちゃうだろう？)\"  Sub vocal 1        Choi Yena\n",
      "2           1  Akimoto Yasushi  \"Suki ni Nacchau Darou? (반해버리잖아? / 好きになっちゃうだろう？)\"  Sub vocal 2  Miyawaki Sakura\n",
      "✅ Sukses simpan 18 baris ke debut_evaluation.json\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "#     DEBUT EVALUATION (debut_evaluation.json)\n",
    "# ==========================================================\n",
    "\n",
    "# Load semua tabel\n",
    "tables = pd.read_html(\"https://akb48.fandom.com/wiki/Produce_48\")\n",
    "\n",
    "# Ambil tabel ke-11\n",
    "table = tables[11]\n",
    "\n",
    "# Cek struktur awal (bisa di-comment kalau sudah yakin)\n",
    "print(\"Kolom awal:\", table.columns.tolist())\n",
    "print(\"Contoh data:\\n\", table.head(3).to_string())\n",
    "\n",
    "# Ambil data dari baris ke-3 (karena baris 1 & 2 biasanya header campuran)\n",
    "data = table.iloc[2:].copy()\n",
    "\n",
    "# Atur ulang nama kolom\n",
    "data.columns = [\n",
    "    \"id_perform\",\n",
    "    \"producer\",\n",
    "    \"original_single\",\n",
    "    \"trainee_position\",\n",
    "    \"trainee_name\"\n",
    "]\n",
    "\n",
    "# cleaning kolom song\n",
    "def clean_quotes(text):\n",
    "    if isinstance(text, str):\n",
    "        text = text.strip()\n",
    "        # Hilangkan hanya kutip ganda luar, tapi biarkan apostrof (kutip tunggal)\n",
    "        if text.startswith('\"') and text.endswith('\"'):\n",
    "            return text[1:-1]\n",
    "    return text\n",
    "\n",
    "data['original_single'] = data['original_single'].apply(clean_quotes)\n",
    "\n",
    "# Drop baris kosong total\n",
    "data = data.dropna(how='all').reset_index(drop=True)\n",
    "\n",
    "# Ganti NaN menjadi string kosong\n",
    "data = data.fillna(\"\")\n",
    "\n",
    "# Ubah ke format list of dict\n",
    "records = data.to_dict(orient=\"records\")\n",
    "\n",
    "# Simpan sebagai JSON\n",
    "output_dir = \"../data/raw\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_file = \"debut_evaluation.json\"\n",
    "\n",
    "with open(os.path.join(output_dir, output_file), \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(records, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"✅ Sukses simpan {len(records)} baris ke {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a0a281",
   "metadata": {},
   "source": [
    "<h3>GENERAL INFO </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "7b7ff8df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kolom awal: ['#', 'Name', 'Agency / Group', 'Votes']\n",
      "Contoh data:\n",
      "    #             Name             Agency / Group   Votes\n",
      "0  1    Jang Wonyoung     Starship Entertainment  338366\n",
      "1  2  Miyawaki Sakura                      HKT48  316105\n",
      "2  3          Jo Yuri  Stone Music Entertainment  294734\n",
      "✅ Sukses simpan 10 baris ke winner.json\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "#     OFFICIAL WINNER (winner.json)\n",
    "# ==========================================================\n",
    "\n",
    "# Load semua tabel\n",
    "tables = pd.read_html(\"https://akb48.fandom.com/wiki/Produce_48\")\n",
    "\n",
    "# Ambil tabel pertama\n",
    "table = tables[0]\n",
    "\n",
    "# Cek struktur awal (bisa di-comment kalau sudah yakin)\n",
    "print(\"Kolom awal:\", table.columns.tolist())\n",
    "print(\"Contoh data:\\n\", table.head(3).to_string())\n",
    "\n",
    "# Ambil data dari baris ke-3 (karena baris 1 & 2 biasanya header campuran)\n",
    "data = table.iloc[2:].copy()\n",
    "\n",
    "# Atur ulang nama kolom\n",
    "data.columns = [\n",
    "    \"rank\",\n",
    "    \"name\",\n",
    "    \"company\",\n",
    "    \"votes\"\n",
    "]\n",
    "\n",
    "# Drop baris kosong total\n",
    "data = data.dropna(how='all').reset_index(drop=True)\n",
    "\n",
    "# Ganti NaN menjadi string kosong\n",
    "data = data.fillna(\"\")\n",
    "\n",
    "# Ubah ke format list of dict\n",
    "records = data.to_dict(orient=\"records\")\n",
    "\n",
    "# Simpan sebagai JSON\n",
    "output_dir = \"../../data\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_file = \"winner.json\"\n",
    "\n",
    "with open(os.path.join(output_dir, output_file), \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(records, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"✅ Sukses simpan {len(records)} baris ke {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5fbe7898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jumlah tabel: 22\n",
      "0 ['Created by', 'Kim Young-bum for Mnet']\n",
      "1 [np.float64(nan), 'Contestants eliminated in the third elimination round']\n",
      "2 ['Kim Min-ju (김민주)', 'Lee Chae-yeon (이채연)', 'Han Cho-won (한초원)', 'Lee Ga-eun (이가은)', 'Miho Miyazaki (宮崎美穂)']\n",
      "3 ['2', '\"Episode 2\"', 'June\\xa022,\\xa02018', nan]\n",
      "5 [np.int64(3), 'Jang Won-young', 'Kwon Eun-bi ↑22', 'Sakura Miyawaki ↑2', 'Jang Won-young ↑1', 'Kang Hye-won ↑22', 'Kang Hye-won =', 'Lee Chae-yeon ↑9', 'Jo Yu-ri ↑15']\n",
      "6 [np.int64(3), 'Jo Yu-ri', np.int64(294734), 'Stone Music']\n",
      "8 ['\"To Reach You\" (너에게 닿기를)', '2018', '57', '61', '—', '30 Girls 6 Concepts', nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]\n",
      "9 ['3', 'June 29, 2018', '1.999%', '2.098%']\n",
      "13 ['China', 'Produce 101 China Chuang 2019 Chuang 2020 Chuang 2021']\n",
      "15 ['48 (IZ*ONE)', 'Jang Won-young Sakura Miyawaki Jo Yu-ri Choi Ye-na An Yu-jin Nako Yabuki Kwon Eun-bi Kang Hye-won Hitomi Honda Kim Chaewon Kim Min-ju Lee Chae-yeon']\n",
      "16 ['48', 'Alex Christine Hong Ye-ji Huh Yunjin Jang Gyu-ri Juri Takahashi Jurina Matsui Kim Do-ah Kim Si-hyeon Mako Kojima Miho Miyazaki Miru Shiroma Miyu Takeuchi Rena Hasegawa Sae Murase Shin Su-hyun Tomu Muto Yūka Kato']\n",
      "19 ['Official Members', \"Saho Iwatate Seina Fukuoka Mion Mukaichi Yui Oguri Narumi Kuranoo (AKB48's Captain & AKB48 Group's\\xa0General Manager) Hiyuka Sakagawa Miu Shitao Ayane Takahashi Remi Tokunaga Serika Nagano Haruna Hashimoto Erii Chiba Kurumi Suzuki Manaka Taguchi Ayami Nagatomo Orin Muto Mizuki Yamauchi Maho Omori Yuki Ota Airi Satō Eriko Hashimoto Nozomi Hatakeyama Yuki Hirata Moka Hotei Mayu Masai Miyu Mizushima Sora Yamazaki Yuna Akiyama Sae Arai Kasumi Kudō Hinano Kubo Yumemi Sako Kohina Narita Azuki Yagi Yui Yamaguchi Manaka Taguchi\"]\n",
      "20 ['Kenkyuusei', 'Momoka Ito Kairi Okumoto Yui Kawamura Sari Shiratori Mei Hanada Saki Oga Saki Kondo Hinata Maruyama']\n"
     ]
    }
   ],
   "source": [
    "# CEK TABEL 2\n",
    "import pandas as pd\n",
    "\n",
    "tables = pd.read_html(\"https://en.wikipedia.org/wiki/Produce_48#Result\", header=None)\n",
    "print(\"Jumlah tabel:\", len(tables))\n",
    "for i, tbl in enumerate(tables):\n",
    "    # Kecualikan tabel terlalu kecil barisnya\n",
    "    if tbl.shape[0] > 3:\n",
    "        print(i, tbl.iloc[2].tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9e817eeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kolom awal: [('Title', 'Title'), ('Year', 'Year'), ('Peak positions', 'KOR [26]'), ('Peak positions', 'KOR Hot 100 [27]'), ('Peak positions', 'JPN Hot 100'), ('Album', 'Album'), ('Unnamed: 6_level_0', 'Unnamed: 6_level_1'), ('Unnamed: 7_level_0', 'Unnamed: 7_level_1'), ('Unnamed: 8_level_0', 'Unnamed: 8_level_1'), ('Unnamed: 9_level_0', 'Unnamed: 9_level_1'), ('Unnamed: 10_level_0', 'Unnamed: 10_level_1'), ('Unnamed: 11_level_0', 'Unnamed: 11_level_1'), ('Unnamed: 12_level_0', 'Unnamed: 12_level_1'), ('Unnamed: 13_level_0', 'Unnamed: 13_level_1'), ('Unnamed: 14_level_0', 'Unnamed: 14_level_1'), ('Unnamed: 15_level_0', 'Unnamed: 15_level_1')]\n",
      "Contoh data:\n",
      "                       Title  Year Peak positions                                             Album Unnamed: 6_level_0 Unnamed: 7_level_0 Unnamed: 8_level_0 Unnamed: 9_level_0 Unnamed: 10_level_0 Unnamed: 11_level_0 Unnamed: 12_level_0 Unnamed: 13_level_0 Unnamed: 14_level_0 Unnamed: 15_level_0\n",
      "                      Title  Year       KOR [26] KOR Hot 100 [27] JPN Hot 100                Album Unnamed: 6_level_1 Unnamed: 7_level_1 Unnamed: 8_level_1 Unnamed: 9_level_1 Unnamed: 10_level_1 Unnamed: 11_level_1 Unnamed: 12_level_1 Unnamed: 13_level_1 Unnamed: 14_level_1 Unnamed: 15_level_1\n",
      "0  \"Pick Me\" (내꺼야; Nekkoya)  2018           —[A]                —        —[B]     Non-album single                NaN                NaN                NaN                NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN\n",
      "1         \"Rollin' Rollin'\"  2018             66               66           —  30 Girls 6 Concepts                NaN                NaN                NaN                NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN\n",
      "2  \"To Reach You\" (너에게 닿기를)  2018             57               61           —  30 Girls 6 Concepts                NaN                NaN                NaN                NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN\n",
      "🧹 Kolom setelah dibersihkan: 16\n",
      "Sukses simpan 12 baris ke single_peak_chart.json\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "#     SINGLES PEAK CHART POSITION(single_peak_chart.json)\n",
    "# ==========================================================\n",
    "\n",
    "# Load semua tabel\n",
    "tables = pd.read_html(\"https://en.wikipedia.org/wiki/Produce_48#Result\")\n",
    "\n",
    "# Ambil tabel ke-8\n",
    "table = tables[8]\n",
    "\n",
    "# Cek struktur (opsional)\n",
    "print(\"Kolom awal:\", table.columns.tolist())\n",
    "print(\"Contoh data:\\n\", table.head(3).to_string())\n",
    "\n",
    "# Ambil data dari baris ke-3 ke bawah\n",
    "data = table.iloc[0:].copy()\n",
    "\n",
    "# Drop semua kolom yang isinya kosong total (semua nilainya NaN)\n",
    "data = data.dropna(axis=1, how='all')\n",
    "\n",
    "# Cek ulang jumlah kolom yang tersisa\n",
    "print(\"🧹 Kolom setelah dibersihkan:\", data.shape[1])\n",
    "\n",
    "# Rename kolom jika jumlahnya sudah tepat (harus 6)\n",
    "data.columns = [\n",
    "    \"song_title\",\n",
    "    \"year\",\n",
    "    \"peak_kor\",\n",
    "    \"kor_hot_100\",\n",
    "    \"jpn_hot_100\",\n",
    "    \"album\",\n",
    "    \"Unused_1\",\n",
    "    \"Unused_2\",\n",
    "    \"Unused_3\",\n",
    "    \"Unused_4\",\n",
    "    \"Unused_5\",\n",
    "    \"Unused_6\",\n",
    "    \"Unused_7\",\n",
    "    \"Unused_8\",\n",
    "    \"Unused_9\",\n",
    "    \"Unused_10\"\n",
    "]\n",
    "\n",
    "data = data[[\"song_title\", \"year\", \"peak_kor\", \"kor_hot_100\", \"jpn_hot_100\", \"album\"]]\n",
    "\n",
    "# cleaning kolom song\n",
    "def clean_quotes(text):\n",
    "    if isinstance(text, str):\n",
    "        text = text.strip()\n",
    "        # Hilangkan hanya kutip ganda luar, tapi biarkan apostrof (kutip tunggal)\n",
    "        if text.startswith('\"') and text.endswith('\"'):\n",
    "            return text[1:-1]\n",
    "    return text\n",
    "\n",
    "data['song_title'] = data['song_title'].apply(clean_quotes)\n",
    "\n",
    "# cleaning angka: \"-\" dan NaN jadi 0, string angka jadi int\n",
    "def safe_int(val):\n",
    "    if pd.isna(val) or val == \"-\" or val == \"\":\n",
    "        return 0\n",
    "    try:\n",
    "        return int(str(val).replace(\",\", \"\").strip())\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "for col in [\"year\", \"peak_kor\", \"kor_hot_100\", \"jpn_hot_100\"]:\n",
    "    data[col] = data[col].apply(safe_int)\n",
    "\n",
    "# Cleaning sekalian baris kosong\n",
    "data = data.dropna(how='all').reset_index(drop=True)\n",
    "\n",
    "# Ganti NaN menjadi string kosong\n",
    "data = data.fillna(\"\")\n",
    "\n",
    "# Ubah ke format list of dict\n",
    "records = data.to_dict(orient=\"records\")\n",
    "\n",
    "# Simpan ke JSON\n",
    "output_dir = \"../data/raw\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_file = \"single_peak_chart.json\"\n",
    "\n",
    "with open(os.path.join(output_dir, output_file), \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(records, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"Sukses simpan {len(records)} baris ke {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "75484773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kolom awal: ['Ep. Ep. Ep.', 'Broadcast date Broadcast date Broadcast date', 'Average audience share AGB Nielsen Nationwide[33]', 'Average audience share AGB Nielsen Seoul[34]']\n",
      "Contoh data:\n",
      "   Ep. Ep. Ep. Broadcast date Broadcast date Broadcast date Average audience share AGB Nielsen Nationwide[33] Average audience share AGB Nielsen Seoul[34]\n",
      "0           1                                June 15, 2018                                            1.132%                                           NR\n",
      "1           2                                June 22, 2018                                            1.913%                                       1.768%\n",
      "2           3                                June 29, 2018                                            1.999%                                       2.098%\n",
      "🧹 Kolom setelah dibersihkan: 4\n",
      "✅ Sukses simpan 13 baris ke episode_rating.json\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "#            RATING PER EPS (episode_rating.json)\n",
    "# ==========================================================\n",
    "\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Load semua tabel\n",
    "tables = pd.read_html(\"https://en.wikipedia.org/wiki/Produce_48#Result\")\n",
    "\n",
    "# Ambil tabel ke-10\n",
    "table = tables[9]\n",
    "\n",
    "# Flatten MultiIndex kolom (tuple menjadi string biasa)\n",
    "table.columns = [' '.join(col).strip() if isinstance(col, tuple) else col for col in table.columns]\n",
    "\n",
    "# Cek struktur (opsional)\n",
    "print(\"Kolom awal:\", table.columns.tolist())\n",
    "print(\"Contoh data:\\n\", table.head(3).to_string())\n",
    "\n",
    "# Buat salinan untuk cleaning\n",
    "data = table.copy()\n",
    "\n",
    "# Drop semua kolom yang isinya kosong total\n",
    "data = data.dropna(axis=1, how='all')\n",
    "\n",
    "# Cek ulang jumlah kolom\n",
    "print(\"🧹 Kolom setelah dibersihkan:\", data.shape[1])\n",
    "\n",
    "# Rename kolom\n",
    "data.columns = [\n",
    "    \"episode\",\n",
    "    \"broadcast_date\",\n",
    "    \"nationwide_rate\",\n",
    "    \"seoul_rate\"\n",
    "]\n",
    "\n",
    "# Fungsi cleaning angka\n",
    "def clean_rate(rate):\n",
    "    if pd.isna(rate) or rate in [\"\", \"NR\"]:\n",
    "        return 0.0\n",
    "    return float(rate.replace(\"%\", \"\").strip())\n",
    "\n",
    "data[\"nationwide_rate\"] = data[\"nationwide_rate\"].apply(clean_rate)\n",
    "data[\"seoul_rate\"] = data[\"seoul_rate\"].apply(clean_rate)\n",
    "\n",
    "# Hapus baris kosong total\n",
    "data = data.dropna(how='all').reset_index(drop=True)\n",
    "\n",
    "# Ganti NaN jadi string kosong\n",
    "data = data.fillna(\"\")\n",
    "\n",
    "# Konversi ke list of dict\n",
    "records = data.to_dict(orient=\"records\")\n",
    "\n",
    "# Simpan ke JSON\n",
    "output_dir = \"../../data\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_file = \"episode_rating.json\"\n",
    "\n",
    "with open(os.path.join(output_dir, output_file), \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(records, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"✅ Sukses simpan {len(records)} baris ke {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e090658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jumlah tabel: 10\n",
      "0 ['Released', 'September\\xa01,\\xa02018', np.float64(nan)]\n",
      "2 [np.float64(3.0), '\"Yume o Miteiru Aida (Korean Version)\" (꿈을 꾸는 동안 (夢を見ている間) Korean Ver.)', 'Yasushi Akimoto', 'Iggy (OREO)Youngbae (RBW)', 'Iggy (OREO)Youngbae (RBW)', '3:28']\n",
      "3 ['China', 'Produce 101 China Chuang 2019 Chuang 2020 Chuang 2021']\n",
      "5 ['48 (IZ*ONE)', 'Jang Won-young Sakura Miyawaki Jo Yu-ri Choi Ye-na An Yu-jin Nako Yabuki Kwon Eun-bi Kang Hye-won Hitomi Honda Kim Chaewon Kim Min-ju Lee Chae-yeon']\n",
      "6 ['48', 'Alex Christine Hong Ye-ji Huh Yunjin Jang Gyu-ri Juri Takahashi Jurina Matsui Kim Do-ah Kim Si-hyeon Mako Kojima Miho Miyazaki Miru Shiroma Miyu Takeuchi Rena Hasegawa Sae Murase Shin Su-hyun Tomu Muto Yūka Kato']\n"
     ]
    }
   ],
   "source": [
    "# CEK TABEL WEBPAGE 3\n",
    "import pandas as pd\n",
    "\n",
    "tables = pd.read_html(\"https://en.wikipedia.org/wiki/30_Girls_6_Concepts\", header=None)\n",
    "print(\"Jumlah tabel:\", len(tables))\n",
    "for i, tbl in enumerate(tables):\n",
    "    # Kecualikan tabel terlalu kecil barisnya\n",
    "    if tbl.shape[0] > 3:\n",
    "        print(i, tbl.iloc[2].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "56e3e391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Sukses gabung 6 + 4 = 10 lagu ke 'singles.json'\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "#    SONGS (singles.json)\n",
    "# ==========================================================\n",
    "\n",
    "def load_and_clean_table(url, table_index):\n",
    "    tables = pd.read_html(url)\n",
    "    table = tables[table_index]\n",
    "\n",
    "    data = table.iloc[0:].copy()\n",
    "\n",
    "    data.columns = [\n",
    "        \"id_single\",\n",
    "        \"title\",\n",
    "        \"lyrics_writer\",\n",
    "        \"music_producer\",\n",
    "        \"arrangement\",\n",
    "        \"duration\"\n",
    "    ]\n",
    "\n",
    "    data = data.fillna(\"\")\n",
    "\n",
    "    return data.to_dict(orient=\"records\")\n",
    "\n",
    "# ===== LOAD DATASET 1 =====\n",
    "songs_1 = load_and_clean_table(\n",
    "    \"https://en.wikipedia.org/wiki/30_Girls_6_Concepts\", \n",
    "    table_index=2\n",
    ")\n",
    "\n",
    "# ===== LOAD DATASET 2 =====\n",
    "songs_2 = load_and_clean_table(\n",
    "    \"https://en.wikipedia.org/wiki/Produce_48_%E2%80%93_Final\", \n",
    "    table_index=2\n",
    ")\n",
    "\n",
    "# ===== GABUNGKAN =====\n",
    "total_songs = songs_1 + songs_2\n",
    "\n",
    "# clean judul lagu\n",
    "def clean_title(title):\n",
    "    title = title.strip()\n",
    "    # \"\\\"Rumor\\\" (H.I.N.P)\" => \"Rumor (H.I.N.P)\"\n",
    "    title = re.sub(r'^\"([^\"]+)\"', r'\\1', title)\n",
    "    return title\n",
    "\n",
    "for i, song in enumerate(total_songs, start=1):\n",
    "    song[\"id_single\"] = str(i)  # Atau f\"{i:02d}\" kalau mau leading zero\n",
    "    song[\"title\"] = clean_title(song[\"title\"])\n",
    "\n",
    "# ===== SIMPAN KE JSON =====\n",
    "output_dir = \"../data/raw\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_file = \"singles.json\"\n",
    "\n",
    "with open(os.path.join(output_dir, output_file), \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(total_songs, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"✅ Sukses gabung {len(songs_1)} + {len(songs_2)} = {len(total_songs)} lagu ke '{output_file}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "1f99b68b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kolom awal: [('Title', 'Title'), ('Details', 'Details'), ('Peak chart positions', 'JPN Hot [22]'), ('Peak chart positions', 'JPN Dig [23]'), ('Peak chart positions', 'US World [24]'), ('Sales', 'Sales')]\n",
      "Contoh data:\n",
      "                  Title                                                                                 Details Peak chart positions                                      Sales\n",
      "                 Title                                                                                 Details         JPN Hot [22] JPN Dig [23] US World [24]           Sales\n",
      "0  30 Girls 6 Concepts    Released: August 18, 2018 Label: Stone Music Entertainment Formats: Digital download                   14            7             9  JPN: 2,473[25]\n",
      "1   Produce 48 – Final  Released: September 1, 2018 Label: Stone Music Entertainment Formats: Digital download                   22            —             —             NaN\n",
      "✅ Sukses simpan 2 baris ke album.json\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "#     ALBUM (album.json)\n",
    "# ==========================================================\n",
    "\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Ambil semua tabel dari Wikipedia\n",
    "tables = pd.read_html(\"https://en.wikipedia.org/wiki/Produce_48#Result\")\n",
    "\n",
    "# Ambil tabel ke-7\n",
    "table = tables[7]\n",
    "\n",
    "# Tampilkan struktur awal (opsional)\n",
    "print(\"Kolom awal:\", table.columns.tolist())\n",
    "print(\"Contoh data:\\n\", table.head(2).to_string())\n",
    "\n",
    "# Ambil baris data aja\n",
    "data = table.iloc[0:].reset_index(drop=True)\n",
    "\n",
    "# Rename kolom\n",
    "data.columns = [\n",
    "    \"title\",\n",
    "    \"details\",\n",
    "    \"jpn_hot\",\n",
    "    \"jpn_digital\",\n",
    "    \"us_world\",\n",
    "    \"sales\"\n",
    "]\n",
    "\n",
    "# =====================\n",
    "# CLEANING FUNCTIONS\n",
    "# =====================\n",
    "\n",
    "def clean_chart(val):\n",
    "    if val == \"—\" or val == \"\":\n",
    "        return 0\n",
    "    return int(val)\n",
    "\n",
    "def clean_sales(val):\n",
    "    if pd.isna(val) or val == \"\":\n",
    "        return 0\n",
    "    val = str(val)\n",
    "    match = re.search(r\"(\\d[\\d,]*)\", val)\n",
    "    if match:\n",
    "        return int(match.group(1).replace(\",\", \"\"))\n",
    "    return 0\n",
    "\n",
    "def parse_details(details):\n",
    "    release_date = \"\"\n",
    "    label = \"\"\n",
    "    formats = \"\"\n",
    "\n",
    "    if isinstance(details, str):\n",
    "        if \"Released:\" in details:\n",
    "            release_date = details.split(\"Released:\")[1].split(\"Label:\")[0].strip()\n",
    "        if \"Label:\" in details:\n",
    "            label = details.split(\"Label:\")[1].split(\"Formats:\")[0].strip()\n",
    "        if \"Formats:\" in details:\n",
    "            formats = details.split(\"Formats:\")[1].strip()\n",
    "\n",
    "    return release_date, label, formats\n",
    "\n",
    "# =====================\n",
    "# APPLY CLEANING\n",
    "# =====================\n",
    "\n",
    "cleaned_records = []\n",
    "\n",
    "for i, row in data.iterrows():\n",
    "    release_date, label, formats = parse_details(row[\"details\"])\n",
    "\n",
    "    cleaned_records.append({\n",
    "        \"title\": row[\"title\"],\n",
    "        \"release_date\": release_date,\n",
    "        \"label\": label,\n",
    "        \"formats\": formats,\n",
    "        \"jpn_hot\": clean_chart(row[\"jpn_hot\"]),\n",
    "        \"jpn_digital\": clean_chart(row[\"jpn_digital\"]),\n",
    "        \"us_world\": clean_chart(row[\"us_world\"]),\n",
    "        \"sales\": clean_sales(row[\"sales\"])\n",
    "    })\n",
    "\n",
    "# =====================\n",
    "# SIMPAN KE JSON\n",
    "# =====================\n",
    "\n",
    "output_dir = \"../../data\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_file = \"album.json\"\n",
    "\n",
    "with open(os.path.join(output_dir, output_file), \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(cleaned_records, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"✅ Sukses simpan {len(cleaned_records)} baris ke {output_file}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
